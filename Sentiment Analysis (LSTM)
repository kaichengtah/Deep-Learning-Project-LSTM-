{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Sentiment Analysis (LSTM)","provenance":[],"collapsed_sections":[],"mount_file_id":"15GKs1kdccx8igGs1plc4oLVOdf2ZSRDW","authorship_tag":"ABX9TyMA9iLO2vcfn0rH1/qxFfqD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Q0NnsShJ8hzY"},"source":["import csv\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LH_FfaWh8uqK"},"source":["def read_csv(filename):\n","    phrase = []\n","    sentiment = []\n","\n","    with open (filename) as csvDataFile:\n","        csvReader = csv.reader(csvDataFile)\n","        next(csvReader, None)\n","\n","        for row in csvReader:\n","            phrase.append(row[1])\n","            sentiment.append(row[2])\n","\n","    X = np.asarray(phrase)\n","    Y = np.asarray(sentiment, dtype=int)\n","\n","    return X, Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hY0RNVz58xcv"},"source":["X_train, Y_train = read_csv('/content/drive/MyDrive/Sentiment Analysis/train_cleaned')\n","X_val, Y_val = read_csv('/content/drive/MyDrive/Sentiment Analysis/val_cleaned')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ueBIaCr82WW"},"source":["maxLen1 = len(max(X_train, key=len).split())\n","maxLen2 = len(max(X_val, key=len).split())\n","maxLen = 35"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yELEBQ-U-AOv","executionInfo":{"status":"ok","timestamp":1637227251639,"user_tz":-480,"elapsed":339,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"8e8d37c9-789c-454b-a5d0-851f555b08a2"},"source":["sentiment = {0:'happy', 1:'sad', 2:'neutral', 3:'fury'}\n","\n","for idx in range(10):\n","    print(X_val[idx] + ' --> ' + sentiment[Y_val[idx]])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["thanks --> neutral\n","really need skateboard --> sad\n","fuckyoumonday like totally crap tastic rainy day / i'm work *hugs* --> sad\n","better check youtube --> neutral\n","welcome last two years flyers fans --> neutral\n","soooo need catch new stuff going airport fly home vegas --> neutral\n","apologize trollcat crap misunderstood concept --> neutral\n","u verse blazing 25mbps anything download though --> neutral\n","heyya guys anyone know give formulas create sudoku please help --> sad\n","correct adore plucked put arm cuz cryin better hahaha --> happy\n"]}]},{"cell_type":"code","metadata":{"id":"1ZDG01g3-Cjm"},"source":["Y_oh_train = tf.one_hot(Y_train, 4)\n","Y_oh_val = tf.one_hot(Y_val, 4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_qEg6c9-FF-","executionInfo":{"status":"ok","timestamp":1637227273243,"user_tz":-480,"elapsed":8,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"2ed0cd8d-4726-4d64-9a29-af2cd8096727"},"source":["for idx in range(5):\n","    print(X_train[idx])\n","    print(Y_oh_train[idx])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["holy crap need see bad gotta wait tomorrow\n","tf.Tensor([1. 0. 0. 0.], shape=(4,), dtype=float32)\n","happy mother's day wonderful women great relaxful day\n","tf.Tensor([1. 0. 0. 0.], shape=(4,), dtype=float32)\n","wishing could nola weekend oh well i'll tuesday\n","tf.Tensor([1. 0. 0. 0.], shape=(4,), dtype=float32)\n","day completed aching clearing trees around beautiful lake splitting headache tho\n","tf.Tensor([1. 0. 0. 0.], shape=(4,), dtype=float32)\n","anything sell album poor thing\n","tf.Tensor([0. 1. 0. 0.], shape=(4,), dtype=float32)\n"]}]},{"cell_type":"code","metadata":{"id":"pkn1iSxu-KJ-"},"source":["def read_glove_vecs(glove_file):\n","    with open(glove_file, 'r') as f:\n","        words = set()\n","        word_to_vec_map = {}\n","        for line in f:\n","            line = line.strip().split()\n","            curr_word = line[0]\n","            words.add(curr_word)\n","            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n","        \n","        i = 1\n","        words_to_index = {}\n","        index_to_words = {}\n","        for w in sorted(words):\n","            words_to_index[w] = i\n","            index_to_words[i] = w\n","            i = i + 1\n","            \n","    return words_to_index, index_to_words, word_to_vec_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1EYGfSO-O0b"},"source":["word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('/content/drive/MyDrive/Sentiment Analysis/glove.6B.50d.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8JtGt2W-Tyz","executionInfo":{"status":"ok","timestamp":1637227320373,"user_tz":-480,"elapsed":23,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"919f8e5d-c292-4ee6-c18e-7f66d962f0db"},"source":["word = \"damn\"\n","idx = 67\n","print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n","print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the index of damn in the vocabulary is 116454\n","the 67th word in the vocabulary is '20s\n"]}]},{"cell_type":"code","metadata":{"id":"Bt_C_pvq-Xqw","executionInfo":{"status":"ok","timestamp":1637228383465,"user_tz":-480,"elapsed":2878,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}}},"source":["import numpy as np\n","import tensorflow\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.initializers import glorot_uniform"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4gvDY7zl-bmO"},"source":["def sentences_to_indices(X, word_to_index, max_len):\n","    \n","    m = X.shape[0]\n","    \n","    X_indices = np.zeros((m, max_len))\n","    \n","    for i in range(m):\n","        sentence_words = X[i].split()\n","        j = 0\n","        for w in sentence_words:\n","            if w not in word_to_index:\n","                X_indices[i, j] = 0\n","            else:\n","                X_indices[i, j] = word_to_index[w]\n","                j += 1\n","    \n","    return X_indices"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDwl76GQ-eVU","executionInfo":{"status":"ok","timestamp":1636110378537,"user_tz":-480,"elapsed":7,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"80b55f64-41bc-4811-8505-0bbcca0f5d20"},"source":["X1 = np.array([\"mother's\", \"lets play baseball\", \"food is ready for you\"])\n","X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n","print(\"X1 =\", X1)\n","print(\"X1_indices =\\n\", X1_indices)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X1 = [\"mother's\" 'lets play baseball' 'food is ready for you']\n","X1_indices =\n"," [[     0.      0.      0.      0.      0.]\n"," [220930. 286375.  69714.      0.      0.]\n"," [151204. 192973. 302254. 151349. 394475.]]\n"]}]},{"cell_type":"code","metadata":{"id":"z1Z5lA20-g9X"},"source":["def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n","    \n","    vocab_size = len(word_to_index) + 1\n","    any_word = list(word_to_vec_map.keys())[0]\n","    emb_dim = word_to_vec_map[any_word].shape[0]\n","\n","    emb_matrix = np.zeros((vocab_size, emb_dim))\n","    \n","    for word, idx in word_to_index.items():\n","        emb_matrix[idx, :] = word_to_vec_map[word]\n","    \n","    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False)\n","\n","    embedding_layer.build((None,))\n","    \n","    embedding_layer.set_weights([emb_matrix])\n","    \n","    return embedding_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dB2a_-sy-kRp"},"source":["def Sentiment_Analysis(input_shape, word_to_vec_map, word_to_index):\n","    \n","    sentence_indices = Input(shape=input_shape, dtype='int32')\n","    \n","    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n","\n","    embeddings = embedding_layer(sentence_indices)\n","    \n","    X = LSTM(units=128, return_sequences=True)(embeddings)\n","    \n","    X = Dropout(rate=0.5)(X)\n","\n","    X = LSTM(units=128)(X)\n","    \n","    X = Dropout(rate=0.5)(X)\n","    \n","    X = Dense(units=4, activation='softmax')(X)\n","    \n","    model = Model(inputs=sentence_indices, outputs=X)\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eq_Iki8M-nJX","executionInfo":{"status":"ok","timestamp":1636110380239,"user_tz":-480,"elapsed":1706,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"3fa9077a-c4e6-4069-8f44-da7dc79f16ce"},"source":["model = Sentiment_Analysis((maxLen,), word_to_vec_map, word_to_index)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 35)]              0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 35, 50)            20000050  \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 35, 128)           91648     \n","_________________________________________________________________\n","dropout (Dropout)            (None, 35, 128)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 128)               131584    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4)                 516       \n","=================================================================\n","Total params: 20,223,798\n","Trainable params: 223,748\n","Non-trainable params: 20,000,050\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"9dbOvPyD-p19"},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKeN32gl-_cg"},"source":["X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1CDtauP1Gv_"},"source":["import os\n","checkpoint_path = \"training_1/cp.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Syv_p-z2_PWM","executionInfo":{"status":"ok","timestamp":1636103292393,"user_tz":-480,"elapsed":921713,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"5259301e-d0f7-430e-a521-e725a73359f7"},"source":["model.fit(X_train_indices, Y_oh_train, epochs = 50, batch_size = 32, shuffle=True, callbacks=[cp_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","750/750 [==============================] - 21s 24ms/step - loss: 1.1435 - accuracy: 0.4641\n","\n","Epoch 00001: saving model to training_1/cp.ckpt\n","Epoch 2/50\n","750/750 [==============================] - 18s 24ms/step - loss: 1.0799 - accuracy: 0.5225\n","\n","Epoch 00002: saving model to training_1/cp.ckpt\n","Epoch 3/50\n","750/750 [==============================] - 18s 24ms/step - loss: 1.0624 - accuracy: 0.5318\n","\n","Epoch 00003: saving model to training_1/cp.ckpt\n","Epoch 4/50\n","750/750 [==============================] - 18s 24ms/step - loss: 1.0441 - accuracy: 0.5432\n","\n","Epoch 00004: saving model to training_1/cp.ckpt\n","Epoch 5/50\n","750/750 [==============================] - 18s 24ms/step - loss: 1.0282 - accuracy: 0.5510\n","\n","Epoch 00005: saving model to training_1/cp.ckpt\n","Epoch 6/50\n","750/750 [==============================] - 18s 24ms/step - loss: 1.0129 - accuracy: 0.5610\n","\n","Epoch 00006: saving model to training_1/cp.ckpt\n","Epoch 7/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9975 - accuracy: 0.5653\n","\n","Epoch 00007: saving model to training_1/cp.ckpt\n","Epoch 8/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9839 - accuracy: 0.5702\n","\n","Epoch 00008: saving model to training_1/cp.ckpt\n","Epoch 9/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9687 - accuracy: 0.5800\n","\n","Epoch 00009: saving model to training_1/cp.ckpt\n","Epoch 10/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9496 - accuracy: 0.5953\n","\n","Epoch 00010: saving model to training_1/cp.ckpt\n","Epoch 11/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9273 - accuracy: 0.6038\n","\n","Epoch 00011: saving model to training_1/cp.ckpt\n","Epoch 12/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.9042 - accuracy: 0.6204\n","\n","Epoch 00012: saving model to training_1/cp.ckpt\n","Epoch 13/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.8786 - accuracy: 0.6300\n","\n","Epoch 00013: saving model to training_1/cp.ckpt\n","Epoch 14/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.8509 - accuracy: 0.6480\n","\n","Epoch 00014: saving model to training_1/cp.ckpt\n","Epoch 15/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.8223 - accuracy: 0.6659\n","\n","Epoch 00015: saving model to training_1/cp.ckpt\n","Epoch 16/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.7939 - accuracy: 0.6791\n","\n","Epoch 00016: saving model to training_1/cp.ckpt\n","Epoch 17/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.7685 - accuracy: 0.6914\n","\n","Epoch 00017: saving model to training_1/cp.ckpt\n","Epoch 18/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.7390 - accuracy: 0.7048\n","\n","Epoch 00018: saving model to training_1/cp.ckpt\n","Epoch 19/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.7082 - accuracy: 0.7209\n","\n","Epoch 00019: saving model to training_1/cp.ckpt\n","Epoch 20/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.6830 - accuracy: 0.7336\n","\n","Epoch 00020: saving model to training_1/cp.ckpt\n","Epoch 21/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.6616 - accuracy: 0.7452\n","\n","Epoch 00021: saving model to training_1/cp.ckpt\n","Epoch 22/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.6258 - accuracy: 0.7617\n","\n","Epoch 00022: saving model to training_1/cp.ckpt\n","Epoch 23/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.6065 - accuracy: 0.7678\n","\n","Epoch 00023: saving model to training_1/cp.ckpt\n","Epoch 24/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.5766 - accuracy: 0.7815\n","\n","Epoch 00024: saving model to training_1/cp.ckpt\n","Epoch 25/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.5578 - accuracy: 0.7912\n","\n","Epoch 00025: saving model to training_1/cp.ckpt\n","Epoch 26/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.5424 - accuracy: 0.7958\n","\n","Epoch 00026: saving model to training_1/cp.ckpt\n","Epoch 27/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.5186 - accuracy: 0.8077\n","\n","Epoch 00027: saving model to training_1/cp.ckpt\n","Epoch 28/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4943 - accuracy: 0.8132\n","\n","Epoch 00028: saving model to training_1/cp.ckpt\n","Epoch 29/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4789 - accuracy: 0.8204\n","\n","Epoch 00029: saving model to training_1/cp.ckpt\n","Epoch 30/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4602 - accuracy: 0.8296\n","\n","Epoch 00030: saving model to training_1/cp.ckpt\n","Epoch 31/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4403 - accuracy: 0.8360\n","\n","Epoch 00031: saving model to training_1/cp.ckpt\n","Epoch 32/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4305 - accuracy: 0.8420\n","\n","Epoch 00032: saving model to training_1/cp.ckpt\n","Epoch 33/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4009 - accuracy: 0.8533\n","\n","Epoch 00033: saving model to training_1/cp.ckpt\n","Epoch 34/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.4015 - accuracy: 0.8530\n","\n","Epoch 00034: saving model to training_1/cp.ckpt\n","Epoch 35/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.3948 - accuracy: 0.8565\n","\n","Epoch 00035: saving model to training_1/cp.ckpt\n","Epoch 36/50\n","750/750 [==============================] - 18s 25ms/step - loss: 0.3712 - accuracy: 0.8661\n","\n","Epoch 00036: saving model to training_1/cp.ckpt\n","Epoch 37/50\n","750/750 [==============================] - 18s 25ms/step - loss: 0.3472 - accuracy: 0.8736\n","\n","Epoch 00037: saving model to training_1/cp.ckpt\n","Epoch 38/50\n","750/750 [==============================] - 18s 25ms/step - loss: 0.3441 - accuracy: 0.8765\n","\n","Epoch 00038: saving model to training_1/cp.ckpt\n","Epoch 39/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.3260 - accuracy: 0.8840\n","\n","Epoch 00039: saving model to training_1/cp.ckpt\n","Epoch 40/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.3272 - accuracy: 0.8832\n","\n","Epoch 00040: saving model to training_1/cp.ckpt\n","Epoch 41/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.3124 - accuracy: 0.8895\n","\n","Epoch 00041: saving model to training_1/cp.ckpt\n","Epoch 42/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.3139 - accuracy: 0.8868\n","\n","Epoch 00042: saving model to training_1/cp.ckpt\n","Epoch 43/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2923 - accuracy: 0.8953\n","\n","Epoch 00043: saving model to training_1/cp.ckpt\n","Epoch 44/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2889 - accuracy: 0.8988\n","\n","Epoch 00044: saving model to training_1/cp.ckpt\n","Epoch 45/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2750 - accuracy: 0.9018\n","\n","Epoch 00045: saving model to training_1/cp.ckpt\n","Epoch 46/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2608 - accuracy: 0.9082\n","\n","Epoch 00046: saving model to training_1/cp.ckpt\n","Epoch 47/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2541 - accuracy: 0.9100\n","\n","Epoch 00047: saving model to training_1/cp.ckpt\n","Epoch 48/50\n","750/750 [==============================] - 18s 25ms/step - loss: 0.2681 - accuracy: 0.9047\n","\n","Epoch 00048: saving model to training_1/cp.ckpt\n","Epoch 49/50\n","750/750 [==============================] - 18s 24ms/step - loss: 0.2552 - accuracy: 0.9112\n","\n","Epoch 00049: saving model to training_1/cp.ckpt\n","Epoch 50/50\n","750/750 [==============================] - 18s 25ms/step - loss: 0.2252 - accuracy: 0.9223\n","\n","Epoch 00050: saving model to training_1/cp.ckpt\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0e5de6ad50>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"q0LM3njR_Sf3","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1637228390322,"user_tz":-480,"elapsed":364,"user":{"displayName":"Tah Kai Cheng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17836633315083266412"}},"outputId":"ed4b7c4a-f69c-4762-84ff-c7be3b6901b0"},"source":["model.load_weights(checkpoint_path)\n","X_val_indices = sentences_to_indices(X_val, word_to_index, maxLen)\n","Y_oh_val = tf.one_hot(Y_val, 4)\n","loss, acc = model.evaluate(X_val_indices, Y_oh_val)\n","print()\n","print(\"Test accuracy = \", acc)"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-80a52ab83051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_oh_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_oh_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"xLH0d7FZ_WFC"},"source":["model.load_weights(checkpoint_path)\n","X_val_indices = sentences_to_indices(X_val, word_to_index, maxLen)\n","pred = model.predict(X_val_indices)\n","for i in range(len(X_val)):\n","    x = X_val_indices\n","    num = np.argmax(pred[i])\n","    if(num != Y_val[i]):\n","        print('Expected sentiment:'+ sentiment[Y_val[i]] + ' //Prediction: '+ X_val[i] + ' --> ' + sentiment[num])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Eb_F9sLBU9L"},"source":["x_test = np.array([''])\n","X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n","print(x_test[0] +' '+  sentiment[np.argmax(model.predict(X_test_indices))])"],"execution_count":null,"outputs":[]}]}